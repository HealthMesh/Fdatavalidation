{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-27T18:21:07.187336Z",
     "start_time": "2024-11-27T18:20:58.874104Z"
    }
   },
   "source": [
    "!pip install rdflib\n",
    "!pip install pandas\n",
    "!pip install pydicom"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdflib in /home/acraf/psr/Fdatavalidation/venv/lib/python3.11/site-packages (7.0.0)\r\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /home/acraf/psr/Fdatavalidation/venv/lib/python3.11/site-packages (from rdflib) (0.6.1)\r\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /home/acraf/psr/Fdatavalidation/venv/lib/python3.11/site-packages (from rdflib) (3.1.4)\r\n",
      "Requirement already satisfied: six in /home/acraf/psr/Fdatavalidation/venv/lib/python3.11/site-packages (from isodate<0.7.0,>=0.6.0->rdflib) (1.16.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: pandas in /home/acraf/psr/Fdatavalidation/venv/lib/python3.11/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/acraf/psr/Fdatavalidation/venv/lib/python3.11/site-packages (from pandas) (2.1.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/acraf/psr/Fdatavalidation/venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/acraf/psr/Fdatavalidation/venv/lib/python3.11/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/acraf/psr/Fdatavalidation/venv/lib/python3.11/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/acraf/psr/Fdatavalidation/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: pydicom in /home/acraf/psr/Fdatavalidation/venv/lib/python3.11/site-packages (2.4.4)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:21:07.200159Z",
     "start_time": "2024-11-27T18:21:07.194361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, pickle, joblib\n",
    "\n",
    "# Get the directory of the current script\n",
    "base_dir = os.getcwd()\n",
    "try:\n",
    "    if folder:\n",
    "        base_dir = os.path.join(base_dir, folder)\n",
    "except:\n",
    "    pass"
   ],
   "id": "4bcc94b4b5f1eb3e",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:21:07.254327Z",
     "start_time": "2024-11-27T18:21:07.248403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from rdflib import *\n",
    "from hashlib import sha256\n",
    "tbox = Namespace('http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/tbox#')\n",
    "abox = Namespace('http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#')\n",
    "dcat = Namespace('https://www.w3.org/ns/dcat#')\n",
    "dcterms = Namespace('http://purl.org/dc/terms/')\n",
    "dqv = Namespace('http://www.w3.org/ns/dqv#')"
   ],
   "id": "4a670ddc66769fa1",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The Profiler is a process which simulates a semi-automatic tools to extract metadata from different data assets. Thus, for tabular data assets the schema is extracted and for Images in DICOM, we extract Header Metadata.",
   "id": "b526dc73679d7564"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:21:07.335167Z",
     "start_time": "2024-11-27T18:21:07.301053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Profiler Class\n",
    "import os\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "class Profiler:\n",
    "    \n",
    "    def __init__(self, file_path, owner=\"Unknown\"):\n",
    "        self.file_path = file_path\n",
    "        self.source_graph = self.create_graph()\n",
    "        self.datasetname = self.self_get_dataset_name()\n",
    "        self.set_owner = self.set_owner(owner)\n",
    "        self.file_extension = self.get_file_extension()\n",
    "        self.technology = self.add_technology()\n",
    "        self.source_graph = self.extract_metadata()\n",
    "        \n",
    "    def create_graph(self):\n",
    "        \"\"\"\n",
    "        This function returns a graph object with the necessary prefixes\n",
    "        :return: RDF Graph\n",
    "        \"\"\"\n",
    "        g = Graph()\n",
    "        g.bind('tb', 'http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/tbox#')\n",
    "        g.bind('ab', 'http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#')\n",
    "        return g\n",
    "    \n",
    "    def set_owner(self, owner):\n",
    "        # Owner Metadata\n",
    "        self.source_graph.add((abox[self.datasetname],  tbox.owner, Literal(owner)))\n",
    "        return owner\n",
    "    \n",
    "    def self_get_dataset_name(self):\n",
    "        \n",
    "        name = os.path.basename(self.file_path).replace('.', '')\n",
    "        # Name Metadata\n",
    "        self.source_graph.add((abox[name], RDF.type, tbox.DataProduct))\n",
    "        identifier = sha256(name.encode('utf-8')).hexdigest()\n",
    "        self.source_graph.add((abox[name],dcterms.identifier, Literal(identifier)))\n",
    "        return name\n",
    "        \n",
    "\n",
    "    def get_file_extension(self):\n",
    "        file_name, file_extension = os.path.splitext(self.file_path)\n",
    "        format = abox.Tabular\n",
    "        if file_extension.lower() == '.csv':\n",
    "            format = abox.Tabular\n",
    "        elif file_extension.lower() == '.dcm':\n",
    "            format = abox.Image\n",
    "        elif file_extension.lower() == '.pkl':\n",
    "            format = abox.ML\n",
    "        \n",
    "        # DataSetTypeTemplate Metadata\n",
    "        self.source_graph.add((format, RDF.type, tbox.DatasetTypeTemplate))\n",
    "        self.source_graph.add((format, dcterms['format'], Literal(file_extension)))  # Correct usage of the namespace\n",
    "        self.source_graph.add((abox[self.datasetname], tbox.hasDTT, format))\n",
    "\n",
    "        return file_extension.lower()\n",
    "    \n",
    "    def generate_unique_uri(self, base_uri):\n",
    "        import uuid\n",
    "        unique_identifier = str(uuid.uuid4())\n",
    "        return URIRef(f\"{base_uri}{unique_identifier}\")\n",
    "    \n",
    "    #DTT\n",
    "    def add_technology(self):\n",
    "        #triple\n",
    "        self.source_graph.add((abox[self.datasetname+\"_TA\"], RDF.type, tbox.TechnologyAspects))\n",
    "        self.source_graph.add((abox[self.datasetname], tbox.hasTA, abox[self.datasetname+\"_TA\"]))\n",
    "\n",
    "        acces_uri = self.generate_unique_uri(abox)\n",
    "        self.source_graph.add((abox[self.datasetname+\"_TA\"], tbox.typeAcces, acces_uri))\n",
    "        self.source_graph.add((acces_uri, RDF.type, tbox.Acces))\n",
    "        self.source_graph.add((acces_uri, RDFS.label, abox.Static))\n",
    "        # PATH\n",
    "        self.source_graph.add((acces_uri, tbox.path, Literal(self.file_path)))\n",
    "\n",
    "    def extract_metadata(self):\n",
    "        if self.file_extension.lower() == '.csv':\n",
    "            return self.extract_csv_metadata()\n",
    "        elif self.file_extension.lower() == '.dcm':\n",
    "            return self.extract_dicom_metadata()\n",
    "        elif self.file_extension.lower() == '.pkl':\n",
    "            return self.extract_csv_metadata(os.path.join(os.path.dirname(self.file_path), \"test.csv\"))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file extension: {self.file_extension}\")\n",
    "            \n",
    "            \n",
    "    def extract_csv_metadata(self, other_file=\"\"):\n",
    "        if other_file:\n",
    "            print(\"OTHERFIle\", other_file)\n",
    "            df = pd.read_csv(other_file)\n",
    "        else:\n",
    "            df = pd.read_csv(self.file_path)\n",
    "        for column in df.columns:\n",
    "            self.source_graph.add((abox[column], RDF.type, tbox.Attribute))\n",
    "            self.source_graph.add((abox[self.datasetname], tbox.hasAttribute, abox[column]))\n",
    "            self.source_graph.add((abox[column], tbox.attribute, Literal(column)))\n",
    "        return self.source_graph\n",
    "\n",
    "    def extract_dicom_metadata(self, n_attributes=50):\n",
    "        ds = pydicom.dcmread(self.file_path)\n",
    "        # Iterate over all attributes\n",
    "        for attribute in dir(ds)[:n_attributes]:\n",
    "            if attribute[0].isalpha():\n",
    "                if hasattr(ds, attribute):\n",
    "                    self.source_graph.add((abox[attribute], RDF.type, tbox.Attribute))\n",
    "                    self.source_graph.add((abox[self.datasetname], tbox.hasAttribute, abox[attribute]))\n",
    "                    self.source_graph.add((abox[attribute], tbox.attribute, Literal(attribute)))\n",
    "        return self.source_graph\n",
    "\n",
    "    def get_source_graph(self):\n",
    "        return self.source_graph\n"
   ],
   "id": "e77fc103b819f2e6",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:21:07.389159Z",
     "start_time": "2024-11-27T18:21:07.385052Z"
    }
   },
   "cell_type": "code",
   "source": "#file_path = \"/home/acraf/psr/Fdatavalidation/DataProductLayer/DataProduct3/Data/Explotation/SurvivalClassifier.pkl\"",
   "id": "9521ab93300bf588",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:21:07.447646Z",
     "start_time": "2024-11-27T18:21:07.442165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    if file_path:\n",
    "        file_path = os.path.join(base_dir, file_path)\n",
    "except:\n",
    "    file_path = input(\"Enter file path: \")\n"
   ],
   "id": "2119ea7442e15d70",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:21:07.524714Z",
     "start_time": "2024-11-27T18:21:07.501117Z"
    }
   },
   "cell_type": "code",
   "source": "profiler = Profiler(file_path)",
   "id": "4a1279da5765e287",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#MGMT_Not Available does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#MGMT_Not Available does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#MGMT_Not Available does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#GTR_over90percent_Not Applicable does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#GTR_over90percent_Not Applicable does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#GTR_over90percent_Not Applicable does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#GTR_over90percent_Not Available does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#GTR_over90percent_Not Available does not look like a valid URI, trying to serialize this will break.\n",
      "http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#GTR_over90percent_Not Available does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OTHERFIle /home/acraf/psr/Fdatavalidation/DataProductLayer/DataProduct3/Data/Explotation/X_test.csv\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:21:07.800218Z",
     "start_time": "2024-11-27T18:21:07.795156Z"
    }
   },
   "cell_type": "code",
   "source": "graph = profiler.get_source_graph()",
   "id": "47148389f4da0fe5",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save Graph to File",
   "id": "76bdfc3fd87537c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:21:08.078400462Z",
     "start_time": "2024-11-27T18:09:08.666164Z"
    }
   },
   "cell_type": "code",
   "source": "sdm = Graph().parse(os.path.join(base_dir, '../../FederatedComputationalGovernance/SemanticDataModel/sdm.ttl'), format='turtle')",
   "id": "ad0deee8b965c21d",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:21:08.078718002Z",
     "start_time": "2024-11-27T18:09:08.718396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sdm = Graph().parse(os.path.join(base_dir, '../../FederatedComputationalGovernance/SemanticDataModel/sdm.ttl'), format='turtle')\n",
    "sdm += graph\n",
    "sdm.serialize(destination=os.path.join(base_dir, '../../FederatedComputationalGovernance/SemanticDataModel/sdm.ttl'), format='turtle')"
   ],
   "id": "e92ec7fe443edd3",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m sdm \u001B[38;5;241m=\u001B[39m Graph()\u001B[38;5;241m.\u001B[39mparse(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(base_dir, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../../FederatedComputationalGovernance/SemanticDataModel/sdm.ttl\u001B[39m\u001B[38;5;124m'\u001B[39m), \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mturtle\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[43msdm\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mgraph\u001B[49m\n\u001B[1;32m      3\u001B[0m sdm\u001B[38;5;241m.\u001B[39mserialize(destination\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(base_dir, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../../FederatedComputationalGovernance/SemanticDataModel/sdm.ttl\u001B[39m\u001B[38;5;124m'\u001B[39m), \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mturtle\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/psr/Fdatavalidation/venv/lib/python3.11/site-packages/rdflib/graph.py:722\u001B[0m, in \u001B[0;36mGraph.__iadd__\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    719\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iadd__\u001B[39m(\u001B[38;5;28mself\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_GraphT\u001B[39m\u001B[38;5;124m\"\u001B[39m, other: Iterable[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_TripleType\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_GraphT\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    720\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Add all triples in Graph other to Graph.\u001B[39;00m\n\u001B[1;32m    721\u001B[0m \u001B[38;5;124;03m    BNode IDs are not changed.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 722\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maddN\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mo\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    723\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
