{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyN4yKHO/AzEIKjUVcLREMGS"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:20:12.519054Z",
     "start_time": "2024-06-08T14:20:12.507373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Get the directory of the current script\n",
    "base_dir = os.getcwd()\n",
    "try:\n",
    "    if folder:\n",
    "        base_dir = os.path.join(base_dir, folder)\n",
    "except:\n",
    "    pass"
   ],
   "outputs": [],
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install rdflib > /dev/null\n",
    "!pip install owlrl > /dev/null\n",
    "!pip install pyshacl > /dev/null"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t3is2tXnQ_8l",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1713774875103,
     "user_tz": -120,
     "elapsed": 13414,
     "user": {
      "displayName": "Achraf Hmimou",
      "userId": "15223621851022794490"
     }
    },
    "outputId": "b71b9038-4d7b-43d6-dc0a-fd590daaaa10",
    "ExecuteTime": {
     "end_time": "2024-06-08T14:20:21.841673Z",
     "start_time": "2024-06-08T14:20:12.597215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "source": [
    "from rdflib import *\n",
    "from owlrl import *\n",
    "import json\n",
    "import pyshacl"
   ],
   "metadata": {
    "id": "kHjZOwhr28_o",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1713774875104,
     "user_tz": -120,
     "elapsed": 10,
     "user": {
      "displayName": "Achraf Hmimou",
      "userId": "15223621851022794490"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-06-08T14:20:21.865314Z",
     "start_time": "2024-06-08T14:20:21.851137Z"
    }
   },
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:20:21.888302Z",
     "start_time": "2024-06-08T14:20:21.872538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tbox = Namespace('http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/tbox#')\n",
    "abox = Namespace('http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#')\n",
    "dcat = Namespace('https://www.w3.org/ns/dcat#')\n",
    "dcterms = Namespace('http://purl.org/dc/terms/')\n",
    "tb = Namespace(\"http://www.semanticweb.org/acraf/ontologies/2021/0/SDM#\")\n",
    "odrl = Namespace(\"http://www.w3.org/ns/odrl/2/\")\n",
    "prov = Namespace(\"http://www.w3.org/ns/prov#\")\n",
    "dqv = Namespace(\"http://www.w3.org/ns/dqv#\")"
   ],
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LOAD CONTRACT"
  },
  {
   "cell_type": "code",
   "source": [
    "contract = Graph()\n",
    "contract.parse(os.path.join(base_dir, \"../../../FederatedComputationalGovernance/SemanticDataModel/sdm.ttl\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mH3rc9etnQtO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1713774875789,
     "user_tz": -120,
     "elapsed": 693,
     "user": {
      "displayName": "Achraf Hmimou",
      "userId": "15223621851022794490"
     }
    },
    "outputId": "c47f473f-7644-4b53-faa6-9c8e2ad726cc",
    "ExecuteTime": {
     "end_time": "2024-06-08T14:20:21.995062Z",
     "start_time": "2024-06-08T14:20:21.897520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nffb351c944204a808a109fccf7167ccd (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 97
  },
  {
   "cell_type": "markdown",
   "source": "# PARSER CONTRACT",
   "metadata": {
    "id": "IYpNSeTH4EUm"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Given a Data Product, Output a DC IRs"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:20:22.013796Z",
     "start_time": "2024-06-08T14:20:22.001018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import uuid\n",
    "\n",
    "def generate_unique_uri(base_uri):\n",
    "    unique_identifier = str(uuid.uuid4())\n",
    "    return URIRef(f\"{base_uri}{unique_identifier}\")"
   ],
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:20:22.033914Z",
     "start_time": "2024-06-08T14:20:22.019793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_jsonld_instances(graph, path):\n",
    "    # Adds JSON-LD instances to the graph\n",
    "    with open(path, 'r') as f:\n",
    "        json_ld_data = json.loads(f.read())\n",
    "        instances = Graph().parse(data=json_ld_data, format='json-ld')\n",
    "        graph += instances\n",
    "    \n",
    "    return graph"
   ],
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:20:22.070111Z",
     "start_time": "2024-06-08T14:20:22.039690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PolicyChecker(Graph):\n",
    "    \n",
    "    \"\"\" Create Policy Checker \"\"\"\n",
    "    def __init__(self, p, p_type, format, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.p = p\n",
    "        self.bind(\"ab\", \"http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#\")\n",
    "        self.bind(\"tb\", \"http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/tbox#\")\n",
    "        self.URI = generate_unique_uri(abox)\n",
    "        self.add((self.URI, RDF.type, tbox.PolicyChecker))\n",
    "        self.add((self.URI, tbox.validates, p))\n",
    "        self.add((self.URI, tbox.hasType, format))\n",
    "        \n",
    "        self.p_type = p_type.split(\"/\")[-1]\n",
    "                \n",
    "    def get_URI(self):\n",
    "        return self.URI\n",
    "    \n",
    "    def get_policy_type(self):\n",
    "        return self.p_type\n",
    "    \n",
    "    def get_policy(self):\n",
    "        return self.p\n",
    "        "
   ],
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:20:22.155409Z",
     "start_time": "2024-06-08T14:20:22.076855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class DCParser:\n",
    "    \"\"\"\n",
    "    Parse Policies of Data Contracts to Policy Checkers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dp, graph):\n",
    "        self.dp = dp\n",
    "        self.g = graph\n",
    "        self.attr_mappings = None\n",
    "\n",
    "    def _validate_graph(self) -> bool:\n",
    "        \"\"\"\n",
    "        Validate the policies grammar is compliant with the grammar defined\n",
    "        :return: conformance/non-conformance\n",
    "        \"\"\"\n",
    "        from pyshacl import validate\n",
    "        shapes = Graph().parse(os.path.join(base_dir, 'policy_grammar.json'), format=\"turtle\")\n",
    "        conforms, report_graph, report_text = validate(self.g,shacl_graph=shapes)\n",
    "        #return boolean\n",
    "        return conforms\n",
    "    \n",
    "    def _read_contracts(self):\n",
    "        \"\"\"\n",
    "        Get the policies associated with a data product\n",
    "        :return: list of policies\n",
    "        \"\"\"\n",
    "        contracts = self.g.objects(subject=abox[self.dp],predicate=tbox.hasDC)\n",
    "        policies_list = []\n",
    "        mappings_dict = {}\n",
    "        for contract in contracts:\n",
    "            # handle policies\n",
    "            policies = self.g.objects(subject=contract,predicate=tbox.hasPolicy)\n",
    "            for policy in policies:\n",
    "                policies_list.append(policy)\n",
    "            # handle mappings    \n",
    "            mappings = self.g.objects(subject=contract,predicate=tbox.hasMapping)\n",
    "            for mapping in mappings:\n",
    "                mfrom = self.g.value(subject=mapping,predicate=tbox.mfrom)\n",
    "                mto = self.g.value(subject=mapping,predicate=tbox.mto)\n",
    "                mappings_dict[mto] = mfrom\n",
    "            \n",
    "        self.attr_mappings = mappings_dict\n",
    "        return policies_list, mappings_dict\n",
    "    \n",
    "    def executRule(self, rule_path, pc, mappings):\n",
    "        \n",
    "        for sparqlrule in os.listdir(rule_path):\n",
    "           with open(os.path.join(rule_path, sparqlrule), 'r') as file:\n",
    "                rule = file.read()\n",
    "                \n",
    "                for key, value in mappings.items():\n",
    "                    rule = rule.replace(f\"<{{{key}}}>\", f\"<{value}>\")\n",
    "            \n",
    "                results = self.g.query(rule)\n",
    "\n",
    "                result_graph = Graph()\n",
    "                \n",
    "                for triple in results:\n",
    "                    result_graph.add(triple)\n",
    "                \n",
    "                pc += result_graph\n",
    "\n",
    "        return pc \n",
    "    \n",
    "    def get_last_op(self, pc):\n",
    "        \n",
    "        last_op = pc.value(subject=pc.get_URI(), predicate=tbox.nextStep)\n",
    "        while last_op:\n",
    "            if not pc.value(subject=last_op, predicate=tbox.nextStep):\n",
    "                break\n",
    "            last_op = pc.value(subject=last_op, predicate=tbox.nextStep)\n",
    "        return last_op\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _initOP(self, policy, pc):\n",
    "        \"\"\"\n",
    "        :param IR: \n",
    "        :param policy: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "        \n",
    "        initOPrules = \"/home/acraf/psr/tfm/Fdatavalidation/SideCar/ValidateContract/parser/rules/initOP\"\n",
    "        mappings = {\n",
    "            \"dp\": abox[self.dp],\n",
    "            \"pc\": pc.get_URI(),\n",
    "            \"op_uri\": generate_unique_uri(abox),\n",
    "        }\n",
    "        pc = self.executRule(initOPrules, pc, mappings)\n",
    "            \n",
    "        return self.get_last_op(pc), pc\n",
    "            \n",
    "            \n",
    "    def _handle_attributes(self, pc): \n",
    "        \n",
    "        operation = pc.get_URI()\n",
    "        while operation:\n",
    "            if pc.value(subject=operation, predicate=tbox.hasAttribute):\n",
    "                attribute = pc.value(subject=operation, predicate=tbox.hasAttribute)\n",
    "                if attribute in self.attr_mappings.keys():\n",
    "                    pc.remove((operation, tbox.hasAttribute, None))\n",
    "                    pc.add((operation, tbox.hasAttribute, self.attr_mappings[attribute]))\n",
    "            operation = pc.value(subject=operation, predicate=tbox.nextStep)\n",
    "        return pc       \n",
    "            \n",
    "        \n",
    "    def _handle_duties(self, pc, initOP):\n",
    "        \"\"\"\n",
    "        :param pc: \n",
    "        :param policy: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "        \n",
    "        initOPrules = \"/home/acraf/psr/tfm/Fdatavalidation/SideCar/ValidateContract/parser/rules/OPS\"\n",
    "        mappings = {\n",
    "            \"dp\": abox[self.dp],\n",
    "            \"pc\": pc.get_URI(),\n",
    "            \"op_uri\": generate_unique_uri(abox),\n",
    "            \"last_op\": initOP,\n",
    "            \"policy_uri\": pc.get_policy(),\n",
    "        }\n",
    "        pc = self.executRule(initOPrules, pc, mappings)\n",
    "        \n",
    "        return self.get_last_op(pc), pc\n",
    "    \n",
    "    def _parse_policy(self, policy):\n",
    "        \"\"\"\n",
    "        Parse the policy to intermediate representation\n",
    "        :param policy: policy to parse\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        \n",
    "        # get policy type\n",
    "        p_type = self.g.value(subject=policy, predicate = RDF.type)\n",
    "        # data format\n",
    "        format = self.g.value(subject=abox[self.dp], predicate = tbox.hasDTT)\n",
    "        # create policy checker graph\n",
    "        pc = PolicyChecker(policy, p_type, format)\n",
    "                \n",
    "        # add initOperation\n",
    "        last_op, pc = self._initOP(policy, pc)\n",
    "        \n",
    "        # handle Duties\n",
    "        last_op, pc = self._handle_duties(pc, last_op)\n",
    "        pc = self._handle_attributes(pc)\n",
    "        # Report\n",
    "        report_uid = generate_unique_uri(abox)\n",
    "        pc.add((last_op, tbox.nextStep, report_uid))\n",
    "        pc.add((report_uid, RDF.type, tbox.Report))\n",
    "        # DUTY\n",
    "        return pc\n",
    "    \n",
    "            \n",
    "    def parse_contracts(self): \n",
    "        \"\"\"\n",
    "        Get the policies associated with a data product\n",
    "        :return: list of policies\n",
    "        \"\"\"\n",
    "        \n",
    "        # validate policies\n",
    "        #if self._validate_graph() == True:\n",
    "            # get policies\n",
    "        policies, mappings = self._read_contracts()\n",
    "               \n",
    "        for policy in policies:   \n",
    "            pc = self._parse_policy(policy)  \n",
    "            self.g = self.g + pc\n",
    "    \n",
    "        self.g.serialize(destination=os.path.join(base_dir, \"generated.ttl\"), format=\"turtle\")\n",
    "        \n",
    "        #self.g.serialize(destination=os.path.join(base_dir, \"../../../FederatedComputationalGovernance/SemanticDataModel/sdm.ttl\"), format=\"turtle\")\n",
    "        \n",
    "        return self.g\n",
    "            #print(pc.serialize(format=\"turtle\"))\n",
    "        #else :\n",
    "        #<   print(\"The policies do not comply with the grammar\")\n",
    "        "
   ],
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:20:22.802092Z",
     "start_time": "2024-06-08T14:20:22.160706Z"
    }
   },
   "cell_type": "code",
   "source": "DCParser(dp, contract).parse_contracts()",
   "outputs": [],
   "execution_count": 102
  }
 ]
}
