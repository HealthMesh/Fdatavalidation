{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyN4yKHO/AzEIKjUVcLREMGS"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:37:45.437905Z",
     "start_time": "2024-05-26T20:37:45.427445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Get the directory of the current script\n",
    "base_dir = os.getcwd()\n",
    "try:\n",
    "    if folder:\n",
    "        base_dir = os.path.join(base_dir, folder)\n",
    "except:\n",
    "    pass"
   ],
   "outputs": [],
   "execution_count": 145
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install rdflib > /dev/null\n",
    "!pip install owlrl > /dev/null\n",
    "!pip install pyshacl > /dev/null"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t3is2tXnQ_8l",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1713774875103,
     "user_tz": -120,
     "elapsed": 13414,
     "user": {
      "displayName": "Achraf Hmimou",
      "userId": "15223621851022794490"
     }
    },
    "outputId": "b71b9038-4d7b-43d6-dc0a-fd590daaaa10",
    "ExecuteTime": {
     "end_time": "2024-05-26T20:37:53.944483Z",
     "start_time": "2024-05-26T20:37:45.584156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 146
  },
  {
   "cell_type": "code",
   "source": [
    "from rdflib import *\n",
    "from owlrl import *\n",
    "import json\n",
    "import pyshacl"
   ],
   "metadata": {
    "id": "kHjZOwhr28_o",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1713774875104,
     "user_tz": -120,
     "elapsed": 10,
     "user": {
      "displayName": "Achraf Hmimou",
      "userId": "15223621851022794490"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-05-26T20:37:53.966020Z",
     "start_time": "2024-05-26T20:37:53.953354Z"
    }
   },
   "outputs": [],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:37:53.986160Z",
     "start_time": "2024-05-26T20:37:53.972552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tbox = Namespace('http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/tbox#')\n",
    "abox = Namespace('http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#')\n",
    "dcat = Namespace('https://www.w3.org/ns/dcat#')\n",
    "dcterms = Namespace('http://purl.org/dc/terms/')\n",
    "tb = Namespace(\"http://www.semanticweb.org/acraf/ontologies/2021/0/SDM#\")\n",
    "odrl = Namespace(\"http://www.w3.org/ns/odrl/2/\")\n",
    "prov = Namespace(\"http://www.w3.org/ns/prov#\")\n",
    "dqv = Namespace(\"http://www.w3.org/ns/dqv#\")"
   ],
   "outputs": [],
   "execution_count": 148
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LOAD CONTRACT"
  },
  {
   "cell_type": "code",
   "source": [
    "contract = Graph()\n",
    "contract.parse(os.path.join(base_dir, \"../../../FederatedComputationalGovernance/SemanticDataModel/sdm.ttl\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mH3rc9etnQtO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1713774875789,
     "user_tz": -120,
     "elapsed": 693,
     "user": {
      "displayName": "Achraf Hmimou",
      "userId": "15223621851022794490"
     }
    },
    "outputId": "c47f473f-7644-4b53-faa6-9c8e2ad726cc",
    "ExecuteTime": {
     "end_time": "2024-05-26T20:37:54.065526Z",
     "start_time": "2024-05-26T20:37:53.994774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N16ac2b9c6b3e450e82c6e82630497880 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 149
  },
  {
   "cell_type": "markdown",
   "source": "# PARSER CONTRACT",
   "metadata": {
    "id": "IYpNSeTH4EUm"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Given a Data Product, Output a DC IRs"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:37:54.082497Z",
     "start_time": "2024-05-26T20:37:54.070689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import uuid\n",
    "\n",
    "def generate_unique_uri(base_uri):\n",
    "    unique_identifier = str(uuid.uuid4())\n",
    "    return URIRef(f\"{base_uri}{unique_identifier}\")"
   ],
   "outputs": [],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:37:54.102532Z",
     "start_time": "2024-05-26T20:37:54.088863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_jsonld_instances(graph, path):\n",
    "    # Adds JSON-LD instances to the graph\n",
    "    with open(path, 'r') as f:\n",
    "        json_ld_data = json.loads(f.read())\n",
    "        instances = Graph().parse(data=json_ld_data, format='json-ld')\n",
    "        graph += instances\n",
    "    \n",
    "    return graph"
   ],
   "outputs": [],
   "execution_count": 151
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:37:54.125936Z",
     "start_time": "2024-05-26T20:37:54.107627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PolicyChecker(Graph):\n",
    "    \n",
    "    \"\"\" Create Policy Checker \"\"\"\n",
    "    def __init__(self, p, p_type, format, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.p = p\n",
    "        self.bind(\"ab\", \"http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#\")\n",
    "        self.bind(\"tb\", \"http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/tbox#\")\n",
    "        self.URI = generate_unique_uri(abox)\n",
    "        self.add((self.URI, RDF.type, tbox.PolicyChecker))\n",
    "        self.add((self.URI, tbox.validates, p))\n",
    "        self.add((self.URI, tbox.hasType, format))\n",
    "        \n",
    "        self.p_type = p_type.split(\"/\")[-1]\n",
    "                \n",
    "    def get_URI(self):\n",
    "        return self.URI\n",
    "    \n",
    "    def get_policy_type(self):\n",
    "        return self.p_type\n",
    "        "
   ],
   "outputs": [],
   "execution_count": 152
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:37:54.223762Z",
     "start_time": "2024-05-26T20:37:54.131173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class DCParser:\n",
    "    \"\"\"\n",
    "    Parse Policies of Data Contracts to Policy Checkers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dp, graph):\n",
    "        self.dp = dp\n",
    "        self.g = graph\n",
    "        self.op_mappings = add_jsonld_instances(Graph(), os.path.join(base_dir, 'operations_mappings.json'))\n",
    "        self.attr_mappings = None\n",
    "\n",
    "    def _validate_graph(self) -> bool:\n",
    "        \"\"\"\n",
    "        Validate the policies grammar is compliant with the grammar defined\n",
    "        :return: conformance/non-conformance\n",
    "        \"\"\"\n",
    "        from pyshacl import validate\n",
    "        shapes = Graph().parse(os.path.join(base_dir, 'policy_grammar.json'), format=\"turtle\")\n",
    "        conforms, report_graph, report_text = validate(self.g,shacl_graph=shapes)\n",
    "        #return boolean\n",
    "        return conforms\n",
    "    \n",
    "    def _read_contracts(self):\n",
    "        \"\"\"\n",
    "        Get the policies associated with a data product\n",
    "        :return: list of policies\n",
    "        \"\"\"\n",
    "        contracts = self.g.objects(subject=abox[self.dp],predicate=tbox.hasDC)\n",
    "        policies_list = []\n",
    "        mappings_dict = {}\n",
    "        for contract in contracts:\n",
    "            # handle mappings\n",
    "            policies = self.g.objects(subject=contract,predicate=tbox.hasPolicy)\n",
    "            for policy in policies:\n",
    "                print(policy)\n",
    "                policies_list.append(policy)\n",
    "                \n",
    "            mappings = self.g.objects(subject=contract,predicate=tbox.hasMapping)\n",
    "            for mapping in mappings:\n",
    "                mfrom = self.g.value(subject=mapping,predicate=tbox.mfrom)\n",
    "                mto = self.g.value(subject=mapping,predicate=tbox.mto)\n",
    "                mappings_dict[mto] = mfrom\n",
    "            \n",
    "        self.attr_mappings = mappings_dict\n",
    "        return policies_list, mappings_dict\n",
    "    \n",
    "    def _get_op(self, operation):\n",
    "    \n",
    "        operation = self.op_mappings.value(subject=operation,predicate=tbox.hasOP)\n",
    "        subgraph = Graph()\n",
    "        # Iterate over all triples in the graph that have the operation as the subject\n",
    "        unique_op = generate_unique_uri(abox)\n",
    "        \n",
    "        for s, p, o in self.op_mappings.triples((operation, None, None)):\n",
    "            # Add each triple to the subgraph\n",
    "            subgraph.add((unique_op, p, o))\n",
    "        \n",
    "        #ADD ABSTRACT OPERATION\n",
    "        subgraph.add((unique_op, tbox.hasAbstract, operation))\n",
    "        subgraph.add(((operation, RDF.type, tbox.AbstractOp)))\n",
    "        \n",
    "        return unique_op, subgraph\n",
    "    \n",
    "    \n",
    "    def _get_op_constraint(self, constraint):\n",
    "        \n",
    "        leftop = self.g.value(subject=constraint, predicate=odrl.leftOperand)\n",
    "        software_agent = self.g.value(subject=leftop, predicate=prov.wasAssociatedWith) \n",
    "        return self._get_op(software_agent)\n",
    "        \n",
    "    \n",
    "    def _get_op_predicate(self, constraint):\n",
    "        rightop = self.g.value(subject=constraint, predicate=odrl.rightOperand)\n",
    "        leftop = self.g.value(subject=constraint, predicate=odrl.leftOperand)\n",
    "        predicate = self.g.value(subject=constraint, predicate=odrl.operator)\n",
    "        if predicate == odrl.lteq:\n",
    "            predicate = Literal(\"<=\")\n",
    "        elif predicate == odrl.gteq:\n",
    "            predicate = Literal(\">=\")\n",
    "        elif predicate == odrl.isA:\n",
    "            predicate = Literal(\"type\")\n",
    "        return (leftop, predicate, rightop)\n",
    "    \n",
    "    def _initOP(self, policy, pc):\n",
    "        \"\"\"\n",
    "        :param IR: \n",
    "        :param policy: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "        ta = self.g.value(subject=abox[self.dp], predicate=tbox.hasTA)\n",
    "        ta_type = self.g.value(subject=ta, predicate=tbox.typeAcces)\n",
    "        ta_type_label = self.g.value(subject=ta_type, predicate=RDFS.label)\n",
    "        \n",
    "        print(ta_type, ta_type_label)\n",
    "        \n",
    "        # Check TA typeAcces\n",
    "        if ta_type_label.split(\"#\")[1] == \"Static\":\n",
    "            \n",
    "            unique_op, subgraph =  self._get_op(ta_type_label)\n",
    "            pc += subgraph\n",
    "            \n",
    "            \n",
    "            if subgraph.value(subject=unique_op, predicate=tbox.hasParameter):\n",
    "                pc.remove((unique_op, tbox.hasParameter, None))\n",
    "                ta_path = self.g.value(subject=ta_type, predicate=tbox.path)\n",
    "                pc.add((unique_op, tbox.hasParameter, ta_path))\n",
    "          \n",
    "            pc.add((pc.get_URI(), tbox.nextStep, unique_op)) \n",
    "            \n",
    "        return unique_op\n",
    "            \n",
    "            \n",
    "    def _handle_attributes(self, pc, operation, attribute):\n",
    "        pc.remove((operation, tbox.hasAttribute, None))\n",
    "        pc.add((operation, tbox.hasAttribute, self.attr_mappings[attribute])) # MAPPING\n",
    "        \n",
    "    def _handle_duties(self, policy, pc, initOP):\n",
    "        \"\"\"\n",
    "        :param pc: \n",
    "        :param policy: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "        \n",
    "        duties = self.g.objects(subject=policy, predicate=odrl.duty)\n",
    "        operation = \"\"\n",
    "        for duty in duties:\n",
    "            \n",
    "            target = self.g.value(subject=duty, predicate = odrl.target)\n",
    "            constraint = self.g.value(subject=duty, predicate = odrl.constraint)\n",
    "            action = self.g.value(subject=duty, predicate = odrl.action)\n",
    "            predicate = self._get_op_predicate(constraint)\n",
    "            \n",
    "            if pc.get_policy_type() == \"dqv#QualityPolicy\": #TODO: FIX THIS\n",
    "                operation = self._get_op_constraint(constraint)\n",
    "                # Operation\n",
    "                pc.add((operation, RDF.type, tbox.Operation))\n",
    "                pc.add((abox.LoadData, tbox.nextStep, operation))\n",
    "                pc.add((operation, tbox.hasParameter, target))\n",
    "               \n",
    "                # Constraint\n",
    "                pc.add((abox.Op1, RDF.type, tbox.Operator))\n",
    "                pc.add((abox.Op1, tbox.operator, Literal(\">=\")))\n",
    "                pc.add((abox.Op1, tbox.hasLeftOperand, predicate[0]))\n",
    "                pc.add((abox.Op1, tbox.hasRightOperand, predicate[2]))\n",
    "                pc.add((operation, tbox.nextStep, abox.Op1))\n",
    "                return abox.Op1\n",
    "            \n",
    "            elif pc.get_policy_type() == \"Privacy\":\n",
    "                \n",
    "                operation, subgraph = self._get_op(action)\n",
    "                pc += subgraph\n",
    "                if subgraph.value(subject=operation, predicate=tbox.hasAttribute):\n",
    "                    self._handle_attributes(pc, operation, target)\n",
    "                pc.add((initOP, tbox.nextStep, operation))    \n",
    "                #if constraint:\n",
    "                #    pc.add((abox.Op2, RDF.type, tbox.Operator))\n",
    "                #    pc.add((abox.LoadData, tbox.nextStep, abox.Op2))\n",
    "                #    pc.add((abox.Op2, tbox.operator, Literal(predicate[1])))\n",
    "                #    pc.add((abox.Op2, tbox.hasLeftOperand, predicate[0]))\n",
    "                #    pc.add((abox.Op2, tbox.hasRightOperand, predicate[2]))\n",
    "                #    pc.add((abox.Op2, tbox.nextStep, operation))\n",
    "                #else:\n",
    "                #pc.add((operation, RDF.type, tbox.Operation))\n",
    "                #pc.add((operation, tbox.hasParameter, target))\n",
    "                return operation\n",
    "    \n",
    "    def _parse_policy(self, policy):\n",
    "        \"\"\"\n",
    "        Parse the policy to intermediate representation\n",
    "        :param policy: policy to parse\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        \n",
    "        # get policy type\n",
    "        p_type = self.g.value(subject=policy, predicate = RDF.type)\n",
    "        # data format\n",
    "        format = self.g.value(subject=abox[self.dp], predicate = tbox.hasDTT)\n",
    "        \n",
    "        # create policy checker graph\n",
    "        pc = PolicyChecker(policy, p_type, format)\n",
    "        \n",
    "        # add initOperation\n",
    "        unique_op = self._initOP(policy, pc)\n",
    "        \n",
    "        # handle Duties\n",
    "        last_op = self._handle_duties(policy, pc, unique_op)\n",
    "        \n",
    "        # Report\n",
    "        pc.add((last_op, tbox.nextStep, abox.Report))\n",
    "        pc.add((abox.Report, RDF.type, tbox.Report))\n",
    "        \n",
    "        # DUTY\n",
    "        return pc\n",
    "    \n",
    "    \n",
    "    def _get_mappings(self):\n",
    "        \"\"\"\n",
    "        Get the mappings associated with a data product\n",
    "        :return: list of mappings\n",
    "        \"\"\"\n",
    "        mappings = self.g.objects(subject=abox[self.dp],predicate=tbox.hasMapping)\n",
    "        mappings_list = []\n",
    "        for mapping in mappings:\n",
    "            mappings_list.append(mapping)\n",
    "            \n",
    "        return mappings_list\n",
    "    \n",
    "            \n",
    "    def parse_contracts(self): \n",
    "        \"\"\"\n",
    "        Get the policies associated with a data product\n",
    "        :return: list of policies\n",
    "        \"\"\"\n",
    "        \n",
    "        # validate policies\n",
    "        #if self._validate_graph() == True:\n",
    "            # get policies\n",
    "        policies, mappings = self._read_contracts()\n",
    "                \n",
    "        #print(policies)\n",
    "        #for policy in policies:\n",
    "           \n",
    "        #parse policy to its ir\n",
    "        pc = self._parse_policy(policies[0])\n",
    "        # pc\n",
    "        e_graph = self.g + pc\n",
    "        # ADD PC to knowledge base\n",
    "        \n",
    "        e_graph.serialize(destination=os.path.join(base_dir, \"../../../FederatedComputationalGovernance/SemanticDataModel/sdm.ttl\"), format=\"turtle\")\n",
    "        \n",
    "            #print(pc.serialize(format=\"turtle\"))\n",
    "        #else :\n",
    "        #<   print(\"The policies do not comply with the grammar\")\n",
    "        "
   ],
   "outputs": [],
   "execution_count": 153
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:37:54.318045Z",
     "start_time": "2024-05-26T20:37:54.244979Z"
    }
   },
   "cell_type": "code",
   "source": "DCParser(dp, contract).parse_contracts()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#p1\n",
      "http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#49a0fb1a-5ea0-4f4b-b0fa-f4dc444598c1 http://www.semanticweb.org/acraf/ontologies/2024/healthmesh/abox#Static\n"
     ]
    }
   ],
   "execution_count": 155
  }
 ]
}
